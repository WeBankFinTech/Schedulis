# Azkaban
default.timezone.id=Asia/Shanghai

# Azkaban JobTypes Plugins
azkaban.jobtype.plugin.dir=plugins/jobtypes

# Loader for projects
executor.global.properties=conf/global.properties
azkaban.project.dir=projects

database.type=mysql
mysql.port=[#DB_PORT]
mysql.host=[#DB_HOST]
mysql.database=[#DB_NAME]
mysql.user=[#DB_USER]
mysql.password=
mysql.numconnections=100

# Azkaban Executor settings
executor.maxThreads=60
executor.port=12321
executor.flow.threads=30
jetty.headerBufferSize=65536
jetty.send.server.version=false
flow.num.job.threads=50
checkers.num.threads=10
executor.server.id=[#SERVER_ID]

# JMX stats
jetty.connector.stats=true
executor.connector.stats=true

# Web Server
azkaban.webserver.url=http://[#WEB_IP]:[#WEB_PORT]

#
# External analyzer settings
# When enabled a button will appear in the flow execution details page which can be accessed
# to query an external analyzer like Dr. Elephant with the flow execution url.
# '%url' in 'execution.external.link.url' will be replaced with flow execution url.
#
# Note: '%url' is used instead of '%flow_exec_id' as flow execution id is not unique
# across azkaban instances. The hostname in the url can be relied upon to distinguish
# between two flows with the same execution id.
#
# Set 'execution.external.link.label' to change the button label. It may be configured
# to reflect the analyzer application.
#
#execution.external.link.url=http://elephant.linkedin.com:8080/search?flow-exec-id=%url
#execution.external.link.label=Dr. Elephant

# uncomment to enable inmemory stats for azkaban
#executor.metric.reports=true
#executor.metric.milisecinterval.default=60000

# Webank alerter settings

# Job memory settins
#job.max.Xms=128M
#job.max.Xmx=512M

proxy.user.lock.down=true

ims.job.report.url=
ims.job.report.subSystemId=
ims.job.report.alertLevel=4
ims.job.register.url=


wtss.web.server.host=
wtss.web.server.port=
wtss.cycle.special.interval=20


flow.paused.max.time.ms=3600000
azkaban.ip.whiteList.enabled=false
azkaban.ip.whiteList=


password.private.key=
executor.job.kill.timeout=60
azkaban.jobcode.prefix=
wtss.dms.url=
wtss.dms.user=
wtss.dms.appid=
wtss.dms.token=
wtss.dms.pagesize=100
job.hook.switch=true
azkaban.holdbatch.operate.ms=30000
azkaban.holdbatch.thread.ms=10000
azkaban.holdbatch.switch=true
webserver.query.interval=10
linkis.num.threads=40

executions.log.retention=true
executions.log.retention.dir=
job.submit.load.check.switch=true
job.submit.load.check.internal=60
job.submit.load.cpu.threshold=0.9
job.submit.load.mem.threshold=0.9
schedulis.exec.conf.dir=
hdfs.log.switch=false
hdfs.log.path=
# hadoop \u914D\u7F6E\u76EE\u5F55
hadoop.conf.dir.path=

wtss.executor.refresh.switch=false
#Executor\u4E0A\u4E0B\u7EBF\u68C0\u67E5\u5F00\u5173
wtss.system.info.check.switch=false
#Executor\u4E0A\u4E0B\u7EBF\u68C0\u67E5\u95F4\u9694s
wtss.system.info.check.interval=1000
#Executor\u4E0A\u4E0B\u7EBF\u68C0\u67E5\u6302\u8F7D\u8DEF\u5F84
wtss.system.info.file.mounted.path=/appcom,/data
#Executor\u4E0A\u4E0B\u7EBF\u68C0\u67E5\u78C1\u76D8\u4F7F\u7528\u7387
wtss.system.info.disk.usage.limit=0.9
#Executor\u4E0A\u4E0B\u7EBF\u68C0\u67E5inode\u4F7F\u7528\u7387
wtss.system.info.inode.usage.limit=0.9